{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpQuVdQYiD0Bt5XPcG3tzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiseongjun/Hands-On-Machine-Learning/blob/main/5_%EC%84%9C%ED%8F%AC%ED%8A%B8_%EB%B2%A1%ED%84%B0_%EB%A8%B8%EC%8B%A0_6_%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. 서포트 벡터 머신**"
      ],
      "metadata": {
        "id": "tN3zcpeR00IY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.1 선형 SVM 분류**"
      ],
      "metadata": {
        "id": "NGsvo9F2pc8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라지 마진 분류**\n",
        "```\n",
        "라지 마진 분류는 SVM의 핵심 개념 중 하나로,\n",
        "데이터를 분류하는 경계와 클래스 간의 마진을 최대화하는 방식을 말합니다.\n",
        "```\n",
        "**서포트 벡터**\n",
        "```\n",
        "클래스는 경계에 위치한 샘플에 의해 전적으로 결정됩니다.\n",
        "이런 샘플을 서포트 벡터라고 합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "MmbXQsutHiAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1.1 소프트 마진 분류**"
      ],
      "metadata": {
        "id": "VIJzNHIOpsFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 샘플이 경계 바깥쪽에 올바르게 분류되어 있다면 이를 하드 마진 분류라고 합니다. 하드 마진 분류에는 두 가지 문제점이 있습니다. 데이터가 선형적으로 구분될 수 있어야 제대로 작동하며 이상치에 민감합니다.\n",
        "\n",
        "이런 문제를 피하려면 더 유연한 모델이 필요합니다. 경계의 폭을 가능한 넓게 유지하는 것과 마진 오류 사이에 적절한 균형을 잡아야 합니다. 이를 소프트 마진 분류라고 합니다."
      ],
      "metadata": {
        "id": "UxojKqIhIQxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "X = iris.data[['petal length (cm)', 'petal width (cm)']].values\n",
        "y = (iris.target == 2) # iris-virginica\n",
        "\n",
        "svm_clf = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(C=1, random_state=42)).fit(X, y)\n",
        "\n",
        "X_new = [[5.5, 1.7], [5.0, 1.5]]\n",
        "print('svm_clf.predict(X_new):\\n {}'.format(svm_clf.predict(X_new)))\n",
        "print('svm_clf.decision_function(X_new):\\n {}'.format(svm_clf.decision_function(X_new)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EgvN73cI9bS",
        "outputId": "5ee166f7-d9eb-46d1-b5b7-2670b5de15cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm_clf.predict(X_new):\n",
            " [ True False]\n",
            "svm_clf.decision_function(X_new):\n",
            " [ 0.66163816 -0.22035761]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.2 비선형 SVM 분류**"
      ],
      "metadata": {
        "id": "P4V9k0f_ECbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비선형 데이터셋을 다루는 한 가지 방법은 다항 특성과 같은 특성을 더 추가하는 것입니다. 사이킷런을 사용하여 이를 구현하기 위해 PolynomialFeatures 변환기와 StandardScaler, LinearSVC를 연결하여 파이프라인을 만듭니다."
      ],
      "metadata": {
        "id": "kxiBolK-KXM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
        "\n",
        "polynomial_svm_clf = make_pipeline(\n",
        "    PolynomialFeatures(degree=3),\n",
        "    StandardScaler(),\n",
        "    LinearSVC(C=10, max_iter=10_000, random_state=42)\n",
        ").fit(X, y)"
      ],
      "metadata": {
        "id": "ikGaiV-8Kk9C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2.1 다항식 커널**"
      ],
      "metadata": {
        "id": "nBZtFM7REHGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "커널 트릭은 실제로는 특성을 추가하지 않으면서 매우 높은 차수의 다항 특성을 많이 추가한 것과 같은 결과를 얻게 해줍니다."
      ],
      "metadata": {
        "id": "w5DBPVQwLfls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "polynomial_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                          SVC(kernel='poly', degree=3, coef0=1, C=5)).fit(X, y)"
      ],
      "metadata": {
        "id": "laRPgXBCLOQw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2.2 유사도 특성 / 5.2.3 가우스 RBF 커널**"
      ],
      "metadata": {
        "id": "HYTCM5AUEPIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가우스 RBF 커널**\n",
        "```\n",
        "가우스 RBF 커널은 SVM에서 사용하는 커널 함수 중 하나입니다.\n",
        "이 커널은 데이터를 고차원 공간으로 매핑하여 선형적으로 분리할 수 있게 만드는 데 사용됩니다.\n",
        "구체적으로, 가우 RBF 커널은 두 점 사이의 거리를 기반으로 값이 결정됩니다.\n",
        "```\n",
        "$$K(x, x^{'}) = exp(-\\frac{||x - x^{'}||^{2}}{2σ^{2}})$$"
      ],
      "metadata": {
        "id": "pm3TmPkuQ1lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                   SVC(kernel='rbf', gamma=5, C=0.001)).fit(X, y)"
      ],
      "metadata": {
        "id": "Nq9niHdPPAsb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2.4 계산 복잡도**"
      ],
      "metadata": {
        "id": "k-fzlOZxEUyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM 분류를 위한 사이킷런 파이썬 클래스 비교**\n",
        "\n",
        "| 파이썬 클래스   | 시간 복잡도   | 외부 메모리 학습 지원   | 스케일 조정의 필요성   | 커널 트릭     |\n",
        "| ------- | ------- | ------- | ------- | ------- |\n",
        "| LinearSVC     | $O(m \\cdot n)$     | 아니오     | 예     | 아니오     |\n",
        "| SVC     | $O(m^{2} \\cdot n)$ ~ $O(m^{3} \\cdot n)$     | 아니오     | 예     | 예     |\n",
        "| SGDClassifier     | $O(m \\cdot n)$     | 예     | 예     | 아니오     |"
      ],
      "metadata": {
        "id": "rhOtul1zNGnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.3 SVM 회귀**\n"
      ],
      "metadata": {
        "id": "O9Fj0RkHEXw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM을 분류가 아니라 회귀에 적용하는 방법은 일정한 마진 오류 안에서 두 클래스 간의 경계 폭이 가능한 최대가 되도록 하는 대신, SVM 회귀는 제한된 마진 오류 안에서 경계 안에 가능한 많은 샘플이 들어가도록 학습합니다.\n",
        "\n",
        "경계의 폭은 하이퍼파라미터 $ϵ$으로 조절합니다."
      ],
      "metadata": {
        "id": "EqdINKT3TDjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = make_pipeline(StandardScaler(),\n",
        "                        LinearSVR(epsilon=0.5, random_state=42)).fit(X, y)\n",
        "svm_poly_reg = make_pipeline(StandardScaler(),\n",
        "                             SVR(kernel='poly', degree=2, C=0.01, epsilon=0.1))"
      ],
      "metadata": {
        "id": "ezK-f1dtT9H9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.4 SVM 이론**"
      ],
      "metadata": {
        "id": "zy6wcSdeEeKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**하드 마진 선형 SVM 분류기의 목적 함수**\n",
        "```\n",
        "하드 마진 선형 SVM 분류기의 목적함수는 주어진 데이터가 선형적으로 구분 가능할 때,\n",
        "두 클래스 간의 경계를 최대화하는 것입니다.\n",
        "이를 통해 새로운 데이터가 주어졌을 때 가장 잘 일반화된 분류기를 만들 수 있습니다.\n",
        "```\n",
        "$$\\min_{w, b}\\frac{1}{2}w^{T}w$$\n",
        "* [조건] $i = 1, 2, \\cdot\\cdot\\cdot, m$일 때 $t^{(i)}(w^{T}x^{(i)} + b) >= 1$\n",
        "\n",
        "**소프트 마진 선형 SVM 분류기의 목적 함수**\n",
        "```\n",
        "소프트 마진 선형 SVM 분류기의 목적함수는 하드 마진 SVM과 비슷하지만,\n",
        "데이터가 선형적으로 완벽하게 구분되지 않는 경우에도 잘 동작하도록 마진과 오차를 모두 고려합니다.\n",
        "이를 통해 모델은 데이터의 잡음이나 일부 오류를 허용하면서도 가능한 한 마진을 크게 만드는 방향으로 학습됩니다.\n",
        "```\n",
        "$$\\min_{w, b, ζ}\\frac{1}{2}w^{T}w + C\\sum^{m}_{i=1}ζ^{(i)}$$\n",
        "* [조건] $i = 1, 2, \\cdot\\cdot\\cdot, m$일 때 $t^{(i)}(w^{T}x^{(i)} + b) >= 1 - ζ^{(i)}$이고 $ζ^{(i)} >= 0$\n",
        "\n",
        "하드 마진과 소프트 마진 문제는 모두 선형적인 제약 조건이 있는 볼록 함수의 이차 최적화 문제입니다. 이런 문제를 콰드라틱 프로그래밍 문제라고 합니다.\n",
        "SVM을 훈련하는 한 가지 방법은 QP 솔버를 사용하는 것입니다. 또 다른 방법은 경사 하강법을 사용하여 힌지 손실 또는 제곱 힌지 손실을 최소화하는 것입니다."
      ],
      "metadata": {
        "id": "vmhbXQdkWyGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.5 쌍대 문제**"
      ],
      "metadata": {
        "id": "UDTGtkZgEgLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.5.1 커널 SVM**"
      ],
      "metadata": {
        "id": "gGMOBgVdEqO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. 결정 트리**"
      ],
      "metadata": {
        "id": "J1eequ7Qxjtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.1 결정 트리 학습과 시각화**"
      ],
      "metadata": {
        "id": "rcStvhwq82aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from graphviz import Source\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "X_iris = iris.data[['petal length (cm)', 'petal width (cm)']].values\n",
        "y_iris = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42).fit(X_iris, y_iris)\n",
        "\n",
        "export_graphviz(\n",
        "    tree_clf,\n",
        "    out_file='iris_tree.dot',\n",
        "    feature_names=['꽃잎 길이 (cm)', '꽃잎 너비 (cm)'],\n",
        "    class_names=iris.target_names,\n",
        "    rounded=True,\n",
        "    filled=True\n",
        ")\n",
        "\n",
        "Source.from_file('iris_tree.dot')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "xtCCRajU9Hll",
        "outputId": "198e10be-6253-437c-80c0-bbf3376feeb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"349pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 349.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 345,-310 345,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M204,-306C204,-306 69,-306 69,-306 63,-306 57,-300 57,-294 57,-294 57,-235 57,-235 57,-229 63,-223 69,-223 69,-223 204,-223 204,-223 210,-223 216,-229 216,-235 216,-235 216,-294 216,-294 216,-300 210,-306 204,-306\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">꽃잎 길이 (cm) &lt;= 2.45</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M105,-179.5C105,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 105,-111.5 105,-111.5 111,-111.5 117,-117.5 117,-123.5 117,-123.5 117,-167.5 117,-167.5 117,-173.5 111,-179.5 105,-179.5\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109.44,-222.91C101.93,-211.65 93.78,-199.42 86.24,-188.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.07,-186.05 80.61,-179.67 83.25,-189.93 89.07,-186.05\"/>\n<text text-anchor=\"middle\" x=\"75.71\" y=\"-200.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M282,-187C282,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 282,-104 282,-104 288,-104 294,-110 294,-116 294,-116 294,-175 294,-175 294,-181 288,-187 282,-187\"/>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">꽃잎 너비 (cm) &lt;= 1.75</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.56,-222.91C169.43,-214.1 175.7,-204.7 181.76,-195.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"184.85,-197.28 187.49,-187.02 179.03,-193.4 184.85,-197.28\"/>\n<text text-anchor=\"middle\" x=\"192.39\" y=\"-207.84\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#4de88e\" stroke=\"black\" d=\"M194,-68C194,-68 97,-68 97,-68 91,-68 85,-62 85,-56 85,-56 85,-12 85,-12 85,-6 91,0 97,0 97,0 194,0 194,0 200,0 206,-6 206,-12 206,-12 206,-56 206,-56 206,-62 200,-68 194,-68\"/>\n<text text-anchor=\"middle\" x=\"145.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n<text text-anchor=\"middle\" x=\"145.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"middle\" x=\"145.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n<text text-anchor=\"middle\" x=\"145.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M188.81,-103.73C183.29,-94.97 177.45,-85.7 171.91,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.78,-74.89 166.48,-68.3 168.85,-78.63 174.78,-74.89\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#843de6\" stroke=\"black\" d=\"M329,-68C329,-68 236,-68 236,-68 230,-68 224,-62 224,-56 224,-56 224,-12 224,-12 224,-6 230,0 236,0 236,0 329,0 329,0 335,0 341,-6 341,-12 341,-12 341,-56 341,-56 341,-62 335,-68 329,-68\"/>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n<text text-anchor=\"middle\" x=\"282.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.82,-103.73C245.26,-94.97 251.01,-85.7 256.48,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"259.52,-78.64 261.82,-68.3 253.57,-74.95 259.52,-78.64\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7d94373d0cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.2 예측**"
      ],
      "metadata": {
        "id": "LJGlakzF941m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**결정 트리의 예측 방법**\n",
        "```\n",
        "트리 구조를 기반으로 데이터를 분할하면서 의사 결정을 내리는 방식으로 작동합니다.\n",
        "결정 트리는 루트 노드에서 시작해서 가지를 따라가며 끝에 리프 노드를 만들게 되는데,\n",
        "이 리프 노드가 최종적인 예측 값 또는 분류 결과를 제공합니다.\n",
        "기본적으로 각 노드는 데이터를 분할하는 기준을 제공하고, 각 분할은 데이터의 속성을 기준으로 이루어집니다.\n",
        "```\n",
        "\n",
        "**지니 불순도**\n",
        "```\n",
        "지니 불순도는 결정 트리 알고리즘에서 데이터를 분할할 때 사용하는 기준 중 하나입니다.\n",
        "이 지표는 특정 데이터 집합이 얼마나 불순한지를 측정하는 데 사용됩니다.\n",
        "즉, 주어진 데이터가 몇 개의 클래스에 속하는지에 따라 그 혼합 정도를 나타냅니다.\n",
        "지니 불순도는 값이 낮을수록 더 순수한 집합을 의미하고, 값이 높을수록 더 혼합된 집합을 의미합니다.\n",
        "결정 트리에서 지니 불순도를 사용하여 데이터를 분할할 때, 분할 후 각 부분이 최대한 순수하도록 하는 방향으로 트리를 만들어 갑니다.\n",
        "```\n",
        "$$G_{i} = 1 - \\sum^{n}_{k=1}p_{i,k}^2$$\n",
        "* $G_{i}$는 i번째 노드의 지니 불순도입니다.\n",
        "* $p_{i,k}$는 $i$번째 노드에 있는 훈련 샘플 중 클래스 $k$에 속한 샘플의 비율입니다."
      ],
      "metadata": {
        "id": "Q4m5ligXlV0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.3 클래스 확률 추정**"
      ],
      "metadata": {
        "id": "R27iUIFImo0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$P(c|t) = \\frac{N_{c}(t)}{N(t)}$$\n",
        "* $N_{c}(t)$: 리프 노드 $t$에 있는 클래스 $c$의 샘플 수\n",
        "* $N(t)$: 리프 노드 $t$에 있는 전체 샘플 수"
      ],
      "metadata": {
        "id": "Z1UbJIZfuVAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('클래스 예측 확률: \\n{}'.format(tree_clf.predict_proba([[5, 1.5]]).round(3)))\n",
        "print('예측 클래스: \\n{}'.format(tree_clf.predict([[5, 1.5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_FO-Dx6mqx-",
        "outputId": "2f6d62a2-ce7d-45ae-8c05-09316c0142e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 예측 확률: \n",
            "[[0.    0.907 0.093]]\n",
            "예측 클래스: \n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.4 CART 훈련 알고리즘**"
      ],
      "metadata": {
        "id": "UqJPAJyrr4Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 훈련 세트를 하나의 특성 $k$의 임곗값 $t_{k}$를 사용해 두 개의 서브셋으로 나눕니다(예 $k$:꽃잎의 길이 <= $t_{k}$: 2.45cm). 크기에 따른 가중치가 적용된 가장 순수한 서브셋으로 나눌 수 있는 ($k$, $t_{k}$) 쌍을 찾습니다. 비용함수를 통해 이 알고리즘을 최소화해야 합니다."
      ],
      "metadata": {
        "id": "Pt7Uge_2tZwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$J(k, t_{k}) = \\frac{m_{left}}{m}G_{left} + \\frac{m_{right}}{m}G_{right}$$\n",
        "* $G_{left/right}$는 왼쪽 / 오른쪽 서브셋의 불순도\n",
        "* $m_{left/right}$는 왼쪽 / 오른쪽 서브셋의 샘플 수"
      ],
      "metadata": {
        "id": "LzQmfimRsSBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART 알고리즘이 훈련 세트를 성공적으로 나누었다면 같은 방식으로 서브셋을 또 나누고 이런 식으로 반복합니다."
      ],
      "metadata": {
        "id": "1HGZCu5PBAUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.5 계산 복잡도**"
      ],
      "metadata": {
        "id": "PJ-BGB_ir69k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측을 하려면 결정 트리를 루트 노드에서부터 리프 노드까지 탐색해야 합니다. 일반적으로 결정 트리는 거의 균형을 이루고 있으므로 결정 트리를 탐색하기 위해서는 약 $O(log_{2}(m))$개 노드를 거쳐야 합니다. 각 노드는 하나의 특성값만 확인하기 때문에 예측에 필요한 전체 복잡도는 특성 수와 무관하게 $O(log_{2}(m))$입니다.\n",
        "\n",
        "훈련 알고리즘은 각 노드에서 모든 훈련 샘플의 모든 특성을 비교합니다. 각 노드에서 모든 샘플의 모든 특성을 비교하면 훈련 복잡도는 $O(n \\cdot mlog_{2}(m))$이 됩니다."
      ],
      "metadata": {
        "id": "lwiKs1YtvuHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.6 지니 불순도 또는 엔트로피?**"
      ],
      "metadata": {
        "id": "ay9Q15840jRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**엔트로피**\n",
        "```\n",
        "엔트로피는 분자의 무질서함을 측정하는 것으로 원래 열역학의 개념입니다.\n",
        "분자가 안정되고 질서정연하면 엔트로피가 0에 가깝습니다.\n",
        "머신러닝에서는 불순도의 측정 방법으로 자주 사용됩니다.\n",
        "어떤 세트가 한 클래스의 샘플만 담고 있다면 엔트로피가 0입니다.\n",
        "```\n",
        "**지니 불순도와 엔트로피 중 어떤 것을 사용해야 할까요?**\n",
        "```\n",
        "실제로는 큰 차이가 없습니다.\n",
        "지니 불순도가 조금 더 계산이 빠르기 때문에 기본값으로 좋습니다.\n",
        "그러나 다른 트리가 만들어지는 경우 지니 불순도는 가장 빈도 높은 클래스를 한쪽 가지로 고립시키는 경향이 있는 반면,\n",
        "엔트로피는 조금 더 균형 잡힌 트리를 만듭니다.\n",
        "```\n",
        "$$H_{i} = -\\sum^{n}_{k=1}p_{i,k}log_{2}(p_{i,k}) \\\\ (p_{i,k} \\neq 0)$$"
      ],
      "metadata": {
        "id": "nezXPDqt1Yib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.7 규제 매개변수**"
      ],
      "metadata": {
        "id": "Tvtlbt6H26_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**비파라미터 모델**\n",
        "```\n",
        "비파라미터 모델은 모델을 학습할 때 고정된 수의 파라미터를 사용하지 않고,\n",
        "데이터를 통해 모델의 구조를 유연하게 정의하는 방식입니다.\n",
        "즉, 모델의 복잡도가 데이터의 양에 따라 달라지며, 특정한 파라미터 수나 형식을 정하지 않고도 데이터에서 직접 정보를 추출합니다.\n",
        "```\n",
        "**DecisionTreeClassifier에는 비슷하게 결정 트리의 형태를 제한하는 다른 하이퍼파라미터가 몇 개 있습니다.**\n",
        "\n",
        "* max_features: 각 노드에서 분할에 사용할 특성의 최대 수\n",
        "* max_leaf_nodes: 리프 노드의 최대 수\n",
        "* min_samples_split: 분할되기 위해 노드가 가져야 하는 최소 샘플 수\n",
        "* min_sample_leaf: 리프 노드가 생성되기 위해 가지고 있어야 할 최소 샘플 수\n",
        "* min_weight_fraction_leaf: min_samples_leaf와 같지만 가중치가 부여된 전체 샘플 수에서의 비율"
      ],
      "metadata": {
        "id": "IKDtm6oI4E4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X_moons, y_moons = make_moons(n_samples=150, noise=0.2, random_state=42)\n",
        "\n",
        "tree_clf1 = DecisionTreeClassifier(random_state=42).fit(X_moons, y_moons)\n",
        "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=5, random_state=42).fit(X_moons, y_moons)\n",
        "\n",
        "X_moons_test, y_moons_test = make_moons(n_samples=1000, noise=0.2,\n",
        "                                        random_state=42)\n",
        "\n",
        "print('tree_clf1.score: {}'.format(tree_clf1.score(X_moons_test, y_moons_test)))\n",
        "print('tree_clf2.score: {}'.format(tree_clf2.score(X_moons_test, y_moons_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "refNx3B95ejx",
        "outputId": "f38d5f4e-0a34-4631-89d2-d0741604ed98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree_clf1.score: 0.901\n",
            "tree_clf2.score: 0.918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.8 회귀**"
      ],
      "metadata": {
        "id": "X05-3jkN5QZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**회귀 CART 알고리즘**\n",
        "```\n",
        "CART 알고리즘은 훈련 세트 불순도를 최소화하는 방향으로 분할하는 대신 MSE를 최소화하도록 분할하는 것을 제외하고는 분류와 거의 비슷하게 작동합니다.\n",
        "```\n",
        "$$J(k,t_{k}) = \\frac{m_{left}}{m}MSE_{left} + \\frac{m_{right}}{m}MSE_{right}$$\n",
        "* $MSE_{mode} = \\frac{1}{m_{node}}\\sum_{i\\in node} (\\hat{y}_{node} - y^{(i)})^2$\n",
        "* $\\hat{y}_{node} = \\frac{1}{m_{node}}\\sum_{i\\in node}y^{(i)}$"
      ],
      "metadata": {
        "id": "k0fHaohO822l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "np.random.seed(42)\n",
        "X_quad = np.random.rand(200, 1) - 0.5 # 랜덤한 하나의 입력 특성\n",
        "y_quad = X_quad ** 2 + 0.025 * np.random.randn(200, 1)\n",
        "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42).fit(X_quad, y_quad)"
      ],
      "metadata": {
        "id": "7s68dNMG8Oxv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.9 축 방향에 대한 민감성**"
      ],
      "metadata": {
        "id": "HmjbABkr8g2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결정 트리는 계단 모양의 결정 경계를 만듭니다(모든 분할은 축에 수직입니다). 그래서 데이터의 방향에 민감합니다.\n",
        "\n",
        "이 문제를 제한하는 한 가지 방법은 데이터의 스케일을 조정한 다음 주성분 분석(PCA) 변환을 적용하는 것입니다."
      ],
      "metadata": {
        "id": "tz91Cw8w_GuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pca_pipeline = make_pipeline(StandardScaler(), PCA())\n",
        "X_iris_rotated = pca_pipeline.fit_transform(X_iris)\n",
        "tree_clf_pca = DecisionTreeClassifier(max_depth=2, random_state=42).fit(X_iris_rotated, y_iris)"
      ],
      "metadata": {
        "id": "FdLjShmg_i7A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.10 결정 트리의 분산 문제**"
      ],
      "metadata": {
        "id": "dT0ZeJdLAFbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 결정 트리의 주요 문제는 분산이 상당히 크다는 것입니다. 즉, 하이퍼파라미터나 데이터를 조금만 변경해도 매우 다른 모델이 생성될 수 있습니다.\n",
        "\n",
        "다행히도 여러 결정 트리의 예측을 평균하면 분산을 크게 줄일 수 있습니다. 이러한 결정 트리의 앙상블을 랜덤 포레스트라고 합니다."
      ],
      "metadata": {
        "id": "P5VR5AocAMao"
      }
    }
  ]
}