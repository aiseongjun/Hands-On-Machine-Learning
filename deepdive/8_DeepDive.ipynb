{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dylw9ewceWrU",
        "XPSzcxu7kw69",
        "mj1rMoOxlTVP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **주성분 분석**\n",
        "```\n",
        "주성분 분석(PCA)은 차원 축소 기법 중에서도 가장 인기 있는 기법입니다.\n",
        "분산이 최대인 축을 찾아 고차원 데이터셋을 주성분으로 변환하는 방식이죠.\n",
        "이를 통해 원본 정보의 대부분을 유지하면서도 차원을 줄일 수 있습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "-4rdPozXcupp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 차원 축소 기법에는 PCA 외에도 여러 기법(Isomap, LDA 등)이 존재합니다. 기법마다 어떤 장단점이 있고, 어떤 경우에 적합할까요?\n",
        "- 비선형성을 가진 분류 문제에서 차원 축소를 할 때 PCA를 사용할 수 있을까요? 더 나은 방법이 있다면, 어떤 방법으로 차원 축소를 할 수 있을까요?\n",
        "- 특정 모델들은 차원 축소의 영향을 크게 받기도 하며, 어떤 모델들은 차원 축소 없이 고차원에서도 성능이 좋게 나오기도 합니다. 차원 축소의 영향을 다르게 받는 모델들의 차이점은 무엇일까요?"
      ],
      "metadata": {
        "id": "PKqOAYK2dJl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **차원 축소 기법에는 PCA 외에도 여러 기법(Isomap, LDA 등)이 존재합니다. 기법마다 어떤 장단점이 있고, 어떤 경우에 적합할까요?**"
      ],
      "metadata": {
        "id": "dylw9ewceWrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Isomap\n",
        "\n",
        "  * 특징\n",
        "    * Isomap은 비선형 차원 축소 기법으로, 데이터의 곡면 상의 거리를 보존하며 저차원으로 투영합니다.\n",
        "    * 주로 비선형 구조를 가진 데이터에서 사용됩니다.\n",
        "\n",
        "  * 장점\n",
        "    * 비선형 구조를 효과적으로 포착합니다.\n",
        "    * 데이터의 지오데식 거리를 보존하여 구조적 특성을 유지합니다.\n",
        "\n",
        "  * 단점\n",
        "    * 계산 비용이 높고, 대규모 데이터셋에 적용하기 어려울 수 있습니다.\n",
        "    * 매개변수 설정에 민감하여 최적화가 필요합니다.\n",
        "  \n",
        "  * 적합한 경우\n",
        "    * 비선형 구조를 가진 데이터셋에서.\n",
        "    * 데이터의 곡면 상의 거리를 보존하며 차원 축소가 필요할 때.\n",
        "\n",
        "2. 선형 판별 분석(LDA, Linear Discriminant Analysis)\n",
        "\n",
        "  * 특징\n",
        "    * LDA는 클래스 간 분산을 최대화하고 클래스 내 분산을 최소화하는 방향으로 데이터를 투영하는 지도 학습 기법입니다.\n",
        "    * 주로 분류 문제에서 사용됩니다.\n",
        "\n",
        "  * 장점\n",
        "    * 클래스 간 분리를 극대화하여 분류 성능을 향상시킵니다.\n",
        "    * 선형 변환을 통해 계산이 효율적입니다.\n",
        "\n",
        "  * 단점\n",
        "    * 데이터가 선형적으로 분리되지 않는 경우 성능이 저하될 수 있습니다.\n",
        "    * 클래스 간 분산이 비슷하지 않거나 클래스 내 분산이 매우 클 때 효과적이지 않을 수 있습니다.\n",
        "\n",
        "  * 적합한 경우\n",
        "    * 클래스 간 분리가 명확한 데이터셋에서.\n",
        "    * 분류 성능 향상이 중요한 경우."
      ],
      "metadata": {
        "id": "x6ulz0TQebcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **비선형성을 가진 분류 문제에서 차원 축소를 할 때 PCA를 사용할 수 있을까요? 더 나은 방법이 있다면, 어떤 방법으로 차원 축소를 할 수 있을까요?**"
      ],
      "metadata": {
        "id": "Tq-kwEugiVGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * 커널 주성분 분석(Kernel PCA):\n",
        "\n",
        "    * 개요: 커널 함수를 사용하여 데이터를 고차원 공간으로 매핑한 후, 그 공간에서 선형적으로 분리 가능한 구조를 찾는 방법입니다. 이를 통해 비선형 데이터의 구조를 효과적으로 반영할 수 있습니다.\n",
        "    * 장점: 비선형 데이터의 복잡한 구조를 반영할 수 있어, 선형 기법으로는 포착하기 어려운 패턴을 발견할 수 있습니다.\n",
        "    * 단점: 계산 비용이 높고, 커널 함수의 선택과 파라미터 튜닝이 필요합니다.\n",
        "  * t-SNE:\n",
        "\n",
        "    * 개요: 고차원 데이터를 저차원으로 변환하면서 데이터 포인트 간의 지역적 구조를 보존하는 비선형 차원 축소 기법입니다.\n",
        "    * 장점: 데이터의 지역적 구조를 잘 보존하여 시각화에 유용하며, 군집 구조를 명확하게 드러낼 수 있습니다.\n",
        "    * 단점: 대규모 데이터셋에 적용하기 어려우며, 파라미터 설정에 민감합니다."
      ],
      "metadata": {
        "id": "ohGBO6t-kNkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **특정 모델들은 차원 축소의 영향을 크게 받기도 하며, 어떤 모델들은 차원 축소 없이 고차원에서도 성능이 좋게 나오기도 합니다. 차원 축소의 영향을 다르게 받는 모델들의 차이점은 무엇일까요?**"
      ],
      "metadata": {
        "id": "XPSzcxu7kw69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 선형 모델의 경우\n",
        "\n",
        "  * 주성분 분석(PCA): PCA는 데이터의 분산을 최대로 보존하는 주성분을 찾아 고차원 데이터를 저차원으로 축소합니다. 이렇게 하면 데이터의 주요 구조를 유지하면서 계산 효율성을 높이고, 노이즈를 줄이며 시각화를 돕는 데 유용합니다.\n",
        "\n",
        "  * 과적합 방지: 고차원 데이터에서는 모델이 학습 데이터에 과도하게 적합되는 과적합(overfitting)의 위험이 증가합니다. 차원 축소를 통해 불필요한 특성을 제거함으로써 과적합을 방지할 수 있습니다.\n",
        "\n",
        "* 비선형 모델의 경우\n",
        "\n",
        "  * 내재된 비선형성: 비선형 모델은 고차원 데이터에서도 복잡한 패턴을 효과적으로 학습할 수 있는 능력을 가지고 있습니다. 따라서 차원 축소 없이도 우수한 성능을 보일 수 있습니다.\n",
        "\n",
        "  * 차원 축소의 영향: 차원 축소는 데이터의 비선형 구조를 왜곡할 수 있어, 비선형 모델의 성능에 부정적인 영향을 미칠 수 있습니다. 따라서 비선형 모델에서는 차원 축소를 신중하게 적용해야 합니다."
      ],
      "metadata": {
        "id": "Z2l3ukc4k0eJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **최적의 클러스터 개수**\n",
        "```\n",
        "이번 주차에서 최적의 클러스터 개수를 찾는 다양한 방법을 배웠습니다!\n",
        "k-평균에서는 이너셔나 실루엣 점수 등을 이용해 클러스터 개수를 선택하고,\n",
        "가우스 혼합에서는 BIC, AIC 등을 이용해 최적의 클러스터 개수를 찾습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "mj1rMoOxlTVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 엘보우 기법에서 엘보우 포인트가 명확히 보이지 않은 경우, 어떻게 해결할 수 있을까요?\n",
        "- 엘보우 기법, 실루엣 점수 등 클러스터 개수를 찾는 방법 마다 최적의 값이 다르게 나오는 경우, 어떤 기준을 따라야 할까요?\n",
        "- 고차원 데이터에서는 최적의 클러스터 개수를 찾는 것이 더욱 어려워집니다. 고차원 데이터에서 최적의 클러스터 개수는 어떻게 찾을까요? 이전에 배웠던 차원 축소를 먼저 적용하는 것이 좋을까요?"
      ],
      "metadata": {
        "id": "u_jBtML7lWzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **엘보우 기법에서 엘보우 포인트가 명확히 보이지 않은 경우, 어떻게 해결할 수 있을까요?**"
      ],
      "metadata": {
        "id": "DSHzPhcElmzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 실루엣 분석 활용: 실루엣 계수는 각 데이터 포인트가 얼마나 잘 클러스터에 속하는지를 측정하는 지표로, -1에서 1 사이의 값을 가집니다. 여러 개의 클러스터 수에 대해 실루엣 계수를 계산하고, 가장 높은 값을 가지는 클러스터 수를 선택하는 방법입니다.\n",
        "\n",
        "2. 다양한 평가 지표 종합: 엘보우 기법과 실루엣 계수 외에도 Davies-Bouldin 지수나 Dunn 지수와 같은 다른 평가 지표를 함께 고려하여 군집화의 품질을 다각도로 평가합니다.\n",
        "\n",
        "3. 도메인 지식 활용: 문제의 특성과 도메인 지식을 바탕으로 군집의 개수를 결정합니다.\n"
      ],
      "metadata": {
        "id": "_rlzIJY645ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **엘보우 기법, 실루엣 점수 등 클러스터 개수를 찾는 방법 마다 최적의 값이 다르게 나오는 경우, 어떤 기준을 따라야 할까요?**"
      ],
      "metadata": {
        "id": "L4r-S29K4Yk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 데이터의 특성 파악: 데이터의 분포와 구조를 시각화하여 군집화가 자연스럽게 이루어지는지 확인합니다.\n",
        "\n",
        "2. 도메인 지식 활용: 문제의 특성과 도메인 지식을 바탕으로 군집의 개수를 결정합니다.\n",
        "\n",
        "3. 다양한 평가 지표 종합: 엘보우 기법과 실루엣 점수 외에도 다른 평가 지표를 함께 고려합니다. 예를 들어, Davies-Bouldin 지수나 Dunn 지수 등을 활용하여 군집화의 품질을 다각도로 평가할 수 있습니다."
      ],
      "metadata": {
        "id": "nsFCv1sA7IMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **고차원 데이터에서는 최적의 클러스터 개수를 찾는 것이 더욱 어려워집니다. 고차원 데이터에서 최적의 클러스터 개수는 어떻게 찾을까요? 이전에 배웠던 차원 축소를 먼저 적용하는 것이 좋을까요?**"
      ],
      "metadata": {
        "id": "KYeQMLzv4b2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 차원 축소 기법 활용:\n",
        "\n",
        "* 주성분 분석(PCA): 데이터의 분산을 최대화하는 주성분을 찾아 고차원 데이터를 저차원으로 축소합니다. 이렇게 하면 데이터의 주요 구조를 유지하면서 분석이 용이해집니다.\n",
        "* t-SNE: 고차원 데이터를 저차원으로 변환하여 데이터의 패턴을 시각적으로 탐색할 수 있게 해주는 비선형 차원 축소 알고리즘입니다.\n",
        "\n",
        "2. 클러스터링 기법 선택:\n",
        "\n",
        "* K-means 클러스터링: 고차원 데이터에서 K-means 알고리즘을 사용할 때는 초기화 전략, 정규화, 거리 계산 최적화 등을 고려해야 합니다. 예를 들어, Elkan의 중점 간 거리 이용법을 활용하여 계산량을 줄일 수 있습니다.\n",
        "\n",
        "3. 평가 지표 활용:\n",
        "\n",
        "* 실루엣 계수: 각 데이터 포인트가 얼마나 잘 클러스터에 속하는지를 측정하는 지표로, -1에서 1 사이의 값을 가집니다. 여러 개의 클러스터 수에 대해 실루엣 계수를 계산하고, 가장 높은 값을 가지는 클러스터 수를 선택하는 방법입니다."
      ],
      "metadata": {
        "id": "oFTKt24U7H7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EM 알고리즘**\n",
        "```\n",
        "k-평균과 달리 EM은 소프트 클러스터 할당을 사용하여, 특정 클러스터에 속할 확률을 예측할 수 있습니다.\n",
        "따라서 EM 알고리즘은 좀 더 유연한 군집 분석이 가능하지만, 항상 더 나은 결과를 보장하지는 않습니다.\n",
        "```"
      ],
      "metadata": {
        "id": "C8Rl9vMVmSVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 클러스터링에서 EM 알고리즘이 K-means보다 항상 더 나은 선택일까요? 소프트 클러스터링이 하드 클러터링이 무조건 더 유리할지 알아봅시다.\n",
        "- 가우스 혼합 모델(GMM) 외에도 EM 알고리즘이 사용되는 머신러닝 기법은 어떤 것이 있을까요?\n",
        "- 비지도 학습에서 이상치 탐지를 할 수 있는 GMM 기반 외의 다른 알고리즘에 대해서 알아보고, 각각의 알고리즘이 어떤 상황에서 유리할지 알아봅시다."
      ],
      "metadata": {
        "id": "jvtBUdTvmT2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**클러스터링에서 EM 알고리즘이 K-means보다 항상 더 나은 선택일까요? 소프트 클러스터링이 하드 클러터링이 무조건 더 유리할지 알아봅시다.**"
      ],
      "metadata": {
        "id": "kGShKZ7qmcF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "소프트 클러스터링(EM 알고리즘)은 데이터 포인트가 여러 클러스터에 속할 수 있는 경우나, 클러스터 간 경계가 명확하지 않은 경우에 유리합니다.\n",
        "반면, 하드 클러스터링(K-means)은 클러스터 간 경계가 명확하고 각 데이터 포인트가 하나의 클러스터에만 속하는 경우에 적합합니다.\n",
        "```"
      ],
      "metadata": {
        "id": "yHpXKzSQqerm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **가우스 혼합 모델(GMM) 외에도 EM 알고리즘이 사용되는 머신러닝 기법은 어떤 것이 있을까요?**"
      ],
      "metadata": {
        "id": "mjNk62ELrWU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **비지도 학습에서 이상치 탐지를 할 수 있는 GMM 기반 외의 다른 알고리즘에 대해서 알아보고, 각각의 알고리즘이 어떤 상황에서 유리할지 알아봅시다.**"
      ],
      "metadata": {
        "id": "wcaNys1ntmG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Isolation Forest**\n",
        "\n",
        "  * 원리: 데이터를 무작위로 분할하여 이상치를 분리하는 트리 구조를 생성합니다.\n",
        "\n",
        "  * 이상치 탐지: 짧은 경로로 분리되는 데이터를 이상치로 간주합니다.\n",
        "\n",
        "  * 적용 상황: 대규모 데이터셋에서 빠르게 이상치를 탐지할 때 유용합니다.\n",
        "\n",
        "2. **One-Class SVM**\n",
        "\n",
        "  * 원리: 주어진 데이터의 경계를 정의하여 정상 데이터를 모델링합니다.\n",
        "\n",
        "  * 이상치 탐지: 모델의 경계를 벗어나는 데이터를 이상치로 식별합니다.\n",
        "\n",
        "  * 적용 상황: 정상 데이터만 존재하는 경우에 효과적입니다.\n",
        "\n",
        "3. **주성분 분석(PCA)**\n",
        "\n",
        "  * 원리: 데이터의 분산이 가장 큰 방향으로 새로운 축을 생성하여 차원을 축소합니다.\n",
        "\n",
        "  * 이상치 탐지: 주요 성분에서 벗어난 데이터를 이상치로 식별합니다.\n",
        "\n",
        "  * 적용 상황: 고차원 데이터에서 차원 축소를 통해 이상치를 탐지할 때 효과적입니다."
      ],
      "metadata": {
        "id": "1T7_wLJvtoLG"
      }
    }
  ]
}