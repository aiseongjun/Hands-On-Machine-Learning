{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **트리 모델에서 사용되는 각각의 Feature Importance 기법들의 특징과 장단점은 무엇인지 고민해보세요!**"
      ],
      "metadata": {
        "id": "hBVsqt9E0fKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Mean Decrease Impurity(MDI)**:\n",
        "\n",
        "* **특징**: 트리 모델에서 각 노드의 불순도 감소를 기반으로 특성의 중요도를 평가합니다. 각 특성이 트리의 분할에 얼마나 기여했는지를 측정합니다.\n",
        "\n",
        "* **장점**: 계산이 빠르고 구현이 간단합니다.\n",
        "\n",
        "* **단점**: 범주형 변수의 경우, 범주의 수가 많을수록 중요도가 과도하게 높게 평가될 수 있습니다. 이는 모델이 범주형 변수를 자주 분할 기준으로 사용하기 때문입니다.\n",
        "\n",
        "2. **Permutation Importance**:\n",
        "\n",
        "* **특징**: 각 특성의 값을 무작위로 섞은 후 모델의 성능 변화를 관찰하여 중요도를 평가합니다. 성능 저하가 클수록 해당 특성의 중요도가 높다고 판단합니다.\n",
        "\n",
        "* **장점**: 모델에 독립적이며, 다양한 모델에서 적용 가능합니다.\n",
        "\n",
        "* **단점**: 계산 비용이 높을 수 있으며, 특히 데이터셋이 클 경우 시간이 많이 소요될 수 있습니다.\n",
        "\n",
        "3. **Drop-Column Importance**:\n",
        "\n",
        "* **특징**: 각 특성을 하나씩 제거한 후 모델을 재학습하여 성능 변화를 측정합니다. 성능 저하가 클수록 해당 특성의 중요도가 높다고 판단합니다.\n",
        "\n",
        "* **장점**: 직관적이며, 모델에 독립적입니다.\n",
        "\n",
        "* **단점**: 모델을 여러 번 재학습해야 하므로 계산 비용이 높습니다.\n",
        "\n",
        "4. **SHAP(SHapley Additive exPlanations)**:\n",
        "\n",
        "* **특징**: 게임 이론의 샤플리 값을 기반으로 각 특성이 예측에 미치는 영향을 정량적으로 평가합니다.\n",
        "\n",
        "* **장점**: 모델에 독립적이며, 각 특성의 기여도를 상세하게 분석할 수 있습니다.\n",
        "\n",
        "* **단점**: 계산이 복잡하고 시간이 많이 소요될 수 있습니다.\n",
        "\n",
        "5. **LIME(Local Interpretable Model-agnostic Explanations)**:\n",
        "\n",
        "* **특징**: 모델의 예측을 근사하는 간단한 모델을 로컬 영역에서 학습하여 특성의 중요도를 평가합니다.\n",
        "\n",
        "* **장점**: 모델에 독립적이며, 개별 예측에 대한 해석이 가능합니다.\n",
        "\n",
        "* **단점**: 로컬 근사 모델의 품질에 따라 결과가 달라질 수 있습니다."
      ],
      "metadata": {
        "id": "nlKUMC9iCBDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tree 계열의 모델들은 다양한 앙상블 기법으로 발전하며 성능을 높여왔습니다. 기본 Tree 모델에서 어떠한 모델들로 발전해왔고, 발전된 모델은 기본 Tree 모델과 어떤 차이를 보이는지, 또는 발전된 모델끼리 어떤 차이를 보이는지 알아봅시다.**"
      ],
      "metadata": {
        "id": "34cgfdYB1lk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **앙상블 기법**:\n",
        "\n",
        "  * **랜덤 포레스트(Random Forest)**:\n",
        "\n",
        "    * **특징**: 여러 개의 결정 트리를 학습시키고, 각 트리의 예측을 종합하여 최종 예측을 도출합니다. 이를 통해 과적합을 방지하고 성능을 향상시킵니다.\n",
        "    * **장점**: 높은 정확도와 안정성을 제공합니다.\n",
        "    * **단점**: 모델이 복잡해져 해석이 어려워질 수 있습니다.\n",
        "2. **부스팅 기법**:\n",
        "  * **특징**: 약한 학습기를 순차적으로 학습시키며, 이전 모델이 잘못 분류한 데이터를 다음 모델이 보완하도록 합니다.\n",
        "  * **장점**: 높은 예측 성능을 보이며, 다양한 데이터 유형에 잘 적용됩니다.\n",
        "  * **단점**: 학습 시간이 길어질 수 있으며, 과적합에 주의해야 합니다.\n",
        "\n",
        "  * **Gradient Boosting**:\n",
        "\n",
        "    * **특징**: 잔차를 예측하는 방식으로 모델을 학습시킵니다.\n",
        "    * **장점**: 높은 예측 성능을 보이며, 다양한 데이터 유형에 잘 적용됩니다.\n",
        "    * **단점**: 학습 시간이 길어질 수 있으며, 과적합에 주의해야 합니다.\n",
        "  * **XGBoost**:\n",
        "\n",
        "    * **특징**: Gradient Boosting의 성능을 개선한 알고리즘으로, 정규화와 병렬 처리를 통해 효율성을 높였습니다.\n",
        "    * **장점**: 빠른 학습 속도와 높은 성능을 제공합니다.\n",
        "    * **단점**: 하이퍼파라미터 튜닝이 복잡할 수 있습니다.\n",
        "  * **LightGBM**:\n",
        "\n",
        "    * **특징**: 대용량 데이터 처리에 최적화된 부스팅 알고리즘으로, 리프 중심의 트리 성장 방식을 사용합니다.\n",
        "    * **장점**: 빠른 학습 속도와 낮은 메모리 사용량을 자랑합니다.\n",
        "    * **단점**: 하이퍼파라미터 튜닝이 필요하며, 작은 데이터셋에서는 성능이 떨어질 수 있습니다.\n",
        "  * **CatBoost**:\n",
        "\n",
        "    * **특징**: 범주형 데이터를 효과적으로 처리할 수 있도록 설계된 부스팅 알고리즘입니다.\n",
        "    * **장점**: 범주형 변수의 전처리 없이도 높은 성능을 발휘합니다.\n",
        "    * **단점**: 다른 부스팅 알고리즘에 비해 학습 속도가 느릴 수 있습니다."
      ],
      "metadata": {
        "id": "LSyjZt8lDZxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **각각의 Tree 모델들이 어떤 데이터에서 적합한지 비교해봅시다. 아래의 내용들을 중심으로, 또는 자신이 추가로 조사한 기준에 대하여 비교하고 분석해봅시다. 마지막으로 각각의 Tree가 어떤 상황에서 쓰이는 게 적합할까요?**"
      ],
      "metadata": {
        "id": "AwIYd6i311qP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델별로 적합한 데이터 특징 분석 (데이터 크기, 결측치, 범주형 변수 등)\n",
        "\n",
        "- 데이터 크기가 **작은 경우 vs 큰 경우**에 적합한 트리 모델은 무엇일까?\n",
        "\n",
        "- **고차원(Feature가 많은 경우)** vs **저차원(Feature가 적은 경우)**에서 트리 모델 성능 비교\n",
        "\n",
        "- 희소 데이터(Sparse Data, 예: One-hot Encoding)에서 트리 모델 비교"
      ],
      "metadata": {
        "id": "VtzC2HHS2AxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**적합한 트리 모델 선택 기준**:\n",
        "\n",
        "  * **데이터 크기**: 데이터가 적을 경우, 모델의 복잡도를 낮추고 교차 검증을 통해 과적합을 방지하는 것이 중요합니다.\n",
        "\n",
        "  * **결측치 처리**: 결측치가 많을 경우, 결측치를 처리하는 능력이 뛰어난 트리 모델을 선택하는 것이 좋습니다.\n",
        "\n",
        "  * **범주형 변수**: 범주형 변수가 많을 경우, 이를 효과적으로 처리할 수 있는 트리 모델을 선택하는 것이 유리합니다.\n",
        "\n",
        "  * **고차원 데이터**: 특징이 많을 경우, 앙상블 기법을 활용하여 과적합을 방지하고 성능을 향상시키는 것이 좋습니다.\n",
        "\n",
        "  * **희소 데이터**: 희소 데이터에서는 트리 모델이 효과적으로 작동하므로, 이를 활용하는 것이 적합합니다."
      ],
      "metadata": {
        "id": "p0VrR8U_2GFr"
      }
    }
  ]
}